{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 13/Set até às 23:59.<br />\n",
    "Grupo: 1 ou 2 pessoas.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO disponibilizar o arquivo com os *access keys/tokens* do Twitter.**\n",
    "\n",
    "\n",
    "### Check 3: \n",
    "\n",
    "Até o dia 06 de Setembro às 23:59, o notebook e o xlsx devem estar no Github com as seguintes evidências: \n",
    "    * Conta no twitter criada.\n",
    "    * Produto escolhido.\n",
    "    * Arquivo Excel contendo a base de treinamento e teste já classificado.\n",
    "    \n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "http://docs.tweepy.org/en/v3.5.0/index.html<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Preparando o ambiente\n",
    "\n",
    "Instalando a biblioteca *tweepy* para realizar a conexão com o Twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as Bibliotecas que serão utilizadas. Esteja livre para adicionar outras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "Para realizar a captura dos dados é necessário ter uma conta cadastrada no twitter:\n",
    "\n",
    "* Conta: ***[Preencha aqui o id da sua conta. Ex: @fulano ]***\n",
    "\n",
    "\n",
    "1. Caso ainda não tenha uma: https://twitter.com/signup\n",
    "1. Depois é necessário registrar um app para usar a biblioteca: https://apps.twitter.com/\n",
    "1. Dentro do registro do App, na aba Keys and Access Tokens, anotar os seguintes campos:\n",
    "    1. Consumer Key (API Key)\n",
    "    1. Consumer Secret (API Secret)\n",
    "1. Mais abaixo, gere um Token e anote também:\n",
    "    1. Access Token\n",
    "    1. Access Token Secret\n",
    "    \n",
    "1. Preencha os valores no arquivo \"auth.pass\"\n",
    "\n",
    "**ATENÇÃO**: Nunca divulgue os dados desse arquivo online (GitHub, etc). Ele contém as chaves necessárias para realizar as operações no twitter de forma automática e portanto é equivalente a ser \"hackeado\". De posse desses dados, pessoas mal intencionadas podem fazer todas as operações manuais (tweetar, seguir, bloquear/desbloquear, listar os seguidores, etc). Para efeito do projeto, esse arquivo não precisa ser entregue!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'auth.pass'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6c5c07e7a31a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[1;31m#leitura do arquivo no formato JSON\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'auth.pass'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'auth.pass'"
     ]
    }
   ],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\"Lucas Tarraf Vaz\"\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\"@lucas\"\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Coletando Dados\n",
    "\n",
    "Agora vamos coletar os dados. Tenha em mente que dependendo do produto escolhido, não haverá uma quantidade significativa de mensagens, ou ainda poder haver muitos retweets.<br /><br /> \n",
    "Configurando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Nintendo Switch'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():    \n",
    "    msgs.append(msg.text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificando as Mensagens\n",
    "\n",
    "Agora você deve abrir o arquivo Excel com as mensagens capturadas e classificar na Coluna B se a mensagem é relevante ou não.<br /> \n",
    "Não se esqueça de colocar um nome para a coluna na célula **B1**.<br /><br />\n",
    "Fazer o mesmo na planilha de Controle.\n",
    "\n",
    "___\n",
    "## Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Escreva o seu código abaixo:\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "dados=pd.read_excel(\"Nintendo Switch.xlsx\")\n",
    "dados2=pd.read_excel(\"Nintendo Switch.xlsx\",sheetname=\"Teste\")\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "#Filtrando caracteres que iriam atrapalhar a precisao da probabilidade\n",
    "\n",
    "def limpar(x,y):\n",
    "    ruim=[\",\",\":\",\".\",\"'\",\";\",\"@\",\"/\",\"#\",\"!\",\"(\",\")\",\"-\"]\n",
    "    lista=[]\n",
    "    for i in x[y]:                      #joga os elemento em uma lista\n",
    "        lista.append(i)  \n",
    "        \n",
    "    for g in range(len(lista)):         #tira as caracteres desnecessarias\n",
    "        for i in lista[g]:\n",
    "            if i in ruim:\n",
    "                lista[g]=lista[g].replace(i,\" \")    \n",
    "                \n",
    "    for i in range(len(lista)):         #tira espacos desnecessarios\n",
    "        lista[i]=re.sub(' +',' ',lista[i])\n",
    "    \n",
    "    for g in range(len(x[y])):          #coloca cada elemento da lista em seu lugar\n",
    "        x[y][g]=lista[g]\n",
    "    \n",
    "    return x\n",
    "\n",
    "dados=limpar(dados,\"Treinamento\")\n",
    "\n",
    "\n",
    "def palavrasposs(x,y):                   # gera lista de todas as palavras possiveis\n",
    "    palavras=[]\n",
    "    for i in range(len(x[y])):\n",
    "        for g in x[y][i].split():\n",
    "            if g not in palavras:\n",
    "                palavras.append(g)\n",
    "    \n",
    "    return palavras\n",
    "\n",
    "\n",
    "def contador_rel_ir(x,y,z,n):            #gera a lista de toas as palavras possiveis na classificacao desejada\n",
    "    index=[]\n",
    "    frases=[]\n",
    "    palavras=[]\n",
    "    for i in range(len(x[z])):\n",
    "        if x[z][i]==n:\n",
    "            index.append(i)\n",
    "    \n",
    "    for i in index:\n",
    "        frases.append(x[y][i])\n",
    "        \n",
    "    for i in range(len(frases)):\n",
    "        for g in frases[i].split():\n",
    "            palavras.append(g)\n",
    "    \n",
    "    return (palavras,index)               \n",
    "\n",
    "def vezes(x,y):                          #Quantas vezes um elemento aparace em uma lista\n",
    "    contador=0\n",
    "    for i in x:\n",
    "        if i==y:\n",
    "            contador=contador+1\n",
    "    return contador\n",
    "            \n",
    "def numero(x,y,z):                       #Quantas vezes um elemento aparace em uma lista(dataframe)\n",
    "    num=0\n",
    "    for i in x[y]:\n",
    "        if i==z:\n",
    "            num=num+1\n",
    "    return num\n",
    "    \n",
    "    return contador\n",
    "\n",
    "def listal(x,y):\n",
    "    lista=[]\n",
    "    for i in range(len(x[y])):         #listal=lista de listas, gera uma lista com palavras sepadaras por frase\n",
    "        a=x[y][i].split() \n",
    "        lista.append(a)\n",
    "    \n",
    "    return lista\n",
    "\n",
    "def frequencia(x,y):                   #quantas vezes um elemento de uma lista de listas apareceu em uma outra lista\n",
    "    lista=[]\n",
    "    for g in range(len(x)):\n",
    "        valores=[]\n",
    "        lista.append(valores)\n",
    "        for i in range(len(x[g])):\n",
    "            valores.append(vezes(y,x[g][i]))\n",
    "    \n",
    "    return lista\n",
    "\n",
    "def Pd_rel_ir(x,y):                    #calcula o P(x/y) \n",
    "    lista=[]\n",
    "    for g in range(len(x)):\n",
    "        valores=[]\n",
    "        lista.append(valores)\n",
    "        for i in range(len(x[g])):\n",
    "            valor=(x[g][i]+1)/y\n",
    "            valores.append(valor)\n",
    "    return lista\n",
    "\n",
    "\n",
    "def multiplica(x):                     #faz a multiplicacao dos elementos de uma lista\n",
    "    cont=1\n",
    "    for i in x:\n",
    "        cont=cont*i\n",
    "    return cont\n",
    "\n",
    "\n",
    "def valorf(x,y):                      #gera o valor final do nayve bayes\n",
    "    valor=[]\n",
    "    for i in range(len(x)):\n",
    "        lista=x[i]\n",
    "        valor.append(multiplica(lista)*(y))\n",
    "    return valor\n",
    "\n",
    "\n",
    "def setdata(x,y,w,z):                 #coloca os valores gerados no novo dataframe\n",
    "    for i in range(len(w)):\n",
    "        if w[i]>z[i]:\n",
    "            x[y][i]=0\n",
    "        else:\n",
    "            x[y][i]=1\n",
    "\n",
    "def percentualCerto(x,y,w,z):\n",
    "    cont=0\n",
    "    for i in z:\n",
    "        if x[y][i]==x[w][i]:\n",
    "            cont=cont+1\n",
    "    return (cont/len(z))*100\n",
    "\n",
    "def percentualErrado(x,y,w,z):\n",
    "    cont=0\n",
    "    for i in z:\n",
    "        if x[y][i]!=x[w][i]:\n",
    "            cont=cont+1\n",
    "    return (cont/len(z))*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3832 3740\n",
      "0.47333333333333333 0.5266666666666666\n"
     ]
    }
   ],
   "source": [
    "relevantep=(len(contador_rel_ir(dados,\"Treinamento\",\"classificado\",1)[0]))\n",
    "irrelevantep=(len(contador_rel_ir(dados,\"Treinamento\",\"classificado\",0)[0]))\n",
    "palavraspos=len(palavrasposs(dados,\"Treinamento\"))\n",
    "\n",
    "relevantemais=relevantep+palavraspos\n",
    "irrelevantemais=irrelevantep+palavraspos\n",
    "Relevante=numero(dados,\"classificado\",1)/len(dados)\n",
    "Irrelevante=numero(dados,\"classificado\",0)/len(dados)\n",
    "\n",
    "print(relevantemais,irrelevantemais)\n",
    "print(Relevante,Irrelevante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "listaFrases=listal(dados2,\"Teste\")\n",
    "PalavrasPosRel=contador_rel_ir(dados,\"Treinamento\",\"classificado\",1)[0]\n",
    "PalavrasPosIrre=contador_rel_ir(dados,\"Treinamento\",\"classificado\",0)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frequenciaRel=(frequencia(listaFrases,PalavrasPosRel))\n",
    "frequenciaIrre=(frequencia(listaFrases,PalavrasPosIrre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PdRelevante=Pd_rel_ir(frequenciaRel,relevantemais)\n",
    "PdIrrelevante=Pd_rel_ir(frequenciaIrre,irrelevantemais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ValorFinalRel=valorf(PdRelevante,Relevante)\n",
    "ValorFinalIrre=valorf(PdIrrelevante,Irrelevante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "setdata(dados2,\"teste\",ValorFinalRel,ValorFinalIrre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>classificado</th>\n",
       "      <th>teste</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"nintendo switch não tem jogo\" tem e é incríve...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gostei de um vídeo @youtube https://t.co/vbhwm...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fire emblem warriors. primeras impresiones par...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>confiram como foi a apresentação dos \"nindies\"...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>luckshot games confirma que sausage sports clu...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rt @techtudo: #fifa18 chega dia 29/09 para xbo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>adicionei um vídeo a uma playlist @youtube htt...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gostei de um vídeo do @youtube https://t.co/5i...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://t.co/prmmdxioxa unlimited é oficialmen...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rumor: nintendo prepara-se para fabricar 18 mi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>e que está sendo criado um port pro nintendo s...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gostei de um vídeo @youtube https://t.co/6htrc...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rt @3dsounada: vice-presidente da xbox adora o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>esses são os próximos nindies chegando para o ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>super mario odyssey (switch): nintendo revela ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Teste  classificado  teste\n",
       "0   \"nintendo switch não tem jogo\" tem e é incríve...             0    1.0\n",
       "1   gostei de um vídeo @youtube https://t.co/vbhwm...             0    1.0\n",
       "2   fire emblem warriors. primeras impresiones par...             0    0.0\n",
       "3   confiram como foi a apresentação dos \"nindies\"...             1    1.0\n",
       "4   luckshot games confirma que sausage sports clu...             1    1.0\n",
       "5   rt @techtudo: #fifa18 chega dia 29/09 para xbo...             1    0.0\n",
       "6   adicionei um vídeo a uma playlist @youtube htt...             0    1.0\n",
       "7   gostei de um vídeo do @youtube https://t.co/5i...             0    1.0\n",
       "8   https://t.co/prmmdxioxa unlimited é oficialmen...             0    0.0\n",
       "9   rumor: nintendo prepara-se para fabricar 18 mi...             0    0.0\n",
       "10  e que está sendo criado um port pro nintendo s...             0    1.0\n",
       "11  gostei de um vídeo @youtube https://t.co/6htrc...             0    1.0\n",
       "12  rt @3dsounada: vice-presidente da xbox adora o...             1    0.0\n",
       "13  esses são os próximos nindies chegando para o ...             1    0.0\n",
       "14  super mario odyssey (switch): nintendo revela ...             1    1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados2.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Opcionalmente:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.274725274725274 12.844036697247708\n",
      "74.72527472527473 87.1559633027523\n"
     ]
    }
   ],
   "source": [
    "indexRel=contador_rel_ir(dados2,\"Teste\",\"classificado\",1)[1]\n",
    "indexIre=contador_rel_ir(dados2,\"Teste\",\"classificado\",0)[1]\n",
    "\n",
    "PosVerdadeiroRe=percentualCerto(dados2,\"classificado\",\"teste\",indexRel)\n",
    "PosVerdadeiroIr=percentualCerto(dados2,\"classificado\",\"teste\",indexIre)\n",
    "PosFalseRe=percentualErrado(dados2,\"classificado\",\"teste\",indexRel)\n",
    "PosFalsoIr=percentualErrado(dados2,\"classificado\",\"teste\",indexIre)\n",
    "\n",
    "print(PosVerdadeiroRe,PosVerdadeiroIr)\n",
    "print(PosFalseRe,PosFalsoIr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Podemos concluir com o arquivo \"TesteProjeto2_CD\" que obtem os mesmo resultados obtidos no exemplo do site \"https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/\" que as funções utilizadas nesse projeto funcionam.\n",
    "Pórem quando utilizadas com uma base de dados muito grande e com muitas palavras expecificas,irônias e links, nosso classificar não obteve um resultado preciso, acertando apenas 25% das frases relevantes e 12% das não relevatens. Isso provavelmente se deve do fato de que para a mensagem ser relevante ela deveria estar com o foco no tema lançamentos e novidades do videogame, fazendo a grande maioria das frases serem relevantes, pois as pessoas comentam muito mais sobre isso do que opiniões pessoais(que foram consideradas irrelevantes).\n",
    "É necessário continuar financiando o projeto pois a classifição manual desses arquivos e práticamenta não viável. E quanto maior for a bases de dados maior será a precisão do classificador.\n",
    "Poderíamos melhorar o classificador  utilizando palavras chave, como \"game,election\", game para esports e elction para eleição, no caso do exeplo do site, essas variáves teriam um peso maior no classificador.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
